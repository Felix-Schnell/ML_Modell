# ğŸš¨ Streamlit App zur Fraud Detection mit Autoencoder

Diese App dient zur **Erkennung potenziell betrÃ¼gerischer Transaktionen (Fraud Detection)** mithilfe eines **Autoencoder-Modells** in einer benutzerfreundlichen **Streamlit-OberflÃ¤che**.

---

## ğŸ“¦ Erforderliche Dateien

Lege **alle folgenden 5 Dateien** in **einen gemeinsamen Ordner** â€“ z.â€¯B. `StreamlitApp/`:

- `streamlit_app.py` â€“ Hauptdatei zum Starten der Web-App
- `autoencoder_model.h5` â€“ Trainiertes Autoencoder-Modell (HDF5)
- `xgboost_model.pkl` â€“ Optionales Vergleichsmodell (XGBoost)
- `scaler.pkl` â€“ Skalierungsobjekt zur Normalisierung der Daten
- `feature_names.pkl` â€“ Liste der erwarteten Feature-Namen

---

## ğŸ—‚ï¸ Beispiel: Ordnerstruktur

StreamlitApp/
â”‚
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ autoencoder_model.h5
â”œâ”€â”€ xgboost_model.pkl
â”œâ”€â”€ scaler.pkl
â””â”€â”€ feature_names.pkl

---

## ğŸš€ Start der App

1. ğŸ“ **Ordner erstellen** â€“ z.â€¯B.:
   ```bash
   C:\Users\DeinName\Desktop\StreamlitApp

2. Alle 5 Dateien in diesen Ordner legen

3. ğŸ’» Terminal/Anaconda Prompt Ã¶ffnen und ins Verzeichnis wechseln:
cd C:\Users\DeinName\Desktop\StreamlitApp

4. App starten mit:
streamlit run streamlit_app.py
(Alternative, je nach installation von Pyhon)
python -m streamlit run streamlit_app.py

5.
Die App Ã¶ffnet sich automatisch im Browser unter:
http://localhost:8501

Vorraussetzung:
Python 3.7+
pip install streamlit pandas scikit-learn keras xgboost

### ğŸ§¾ CSV-Format fÃ¼r Streamlit-Upload")

    """
    Die Streamlit-App erwartet eine CSV-Datei im Format von `df_model_ready_test.csv`,  
    das in der Datei `Fertige_Pipeline.ipynb` bzw. in der Modellpipeline generiert wird.

    #### BenÃ¶tigte Spalten:
    - `sales_price_sum_x`  
    - `sales_price_mean_x`  
    - `sales_price_max_x`  
    - `camera_certainty_mean_x`  
    - `camera_certainty_min_x`  
    - `was_voided_sum_x`  
    - `category_nunique_x`  
    - `sold_by_weight_sum_x`  
    - `age_restricted_sum_x`  
    - `opening_date`  
    - `has_cash_payment`  
    - `average_price_per_article`  
    - `transaction_duration_seconds`  
    - `articles_per_minute`  
    - `voided_articles_ratio`  
    - `hour`  
    - `weekday`  
    - `snack_count`  
    - `snack_share`

    > âš ï¸ Hinweis: Der Dateiname spielt keine Rolle â€“ wichtig ist, dass die Spalten exakt so heiÃŸen und mit denen Ã¼bereinstimmen, die vom Modell erwartet werden.
    """
    âš ï¸ Damit die Analyse funktioniert, muss die Datei `Fertige_Pipeline.ipynb` einmal korrekt ausgefÃ¼hrt worden sein,  
    da sie die benÃ¶tigten Features und Modellstrukturen erstellt.  
    Die resultierende Datei `df_model_ready_test.csv` (bzw. ein Teil davon) kann dann in Streamlit verwendet werden.
    """
)

